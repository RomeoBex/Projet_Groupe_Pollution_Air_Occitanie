---
title: "Projet Pollution"
author: "BEX Roméo"
date : today
format:
  revealjs: 
    theme: default
    title-slide-attributes:
        data-background-image: bg_slides.svg 
    transition: slide
---

# Objectifs du projet {background-color="#CAFFEF"}
::: {.incremental}
- Etablir une corrélation entre pollution en Occitanie et météo 
- Etablir une hiérarchie des villes en fonction du taux de pollution des principaux polluants 
:::


## Technicité et source {background-color="#CAFFEF"}
:::{.incremental}
- Bibilothèques : 
    + pandas
    + matplotlib
    + seaborn
    + os
    + geojson
  
- Diapositives : [Quarto](https://quarto.org/)
- Sources : [données SYNOP](https://public.opendatasoft.com/explore/dataset/donnees-synop-essentielles-omm/api/?sort=date)
           et [Atmo Occitanie](https://data-atmo-occitanie.opendata.arcgis.com/pages/liste-des-flux)
:::


# Analyse du code {background-color="#CAFFEF"}
```{.python code-line-numbers="2,3,4,5,6|9|12|15|18,19|22,23,24,25|27"}

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import seaborn as sns
import os 

# Remplacez 'votre_fichier.csv' par le chemin vers votre fichier CSV
chemin_fichier_csv = 'Mesure_mensuelle_Region_Occitanie_Polluants_Principaux.csv'

# Charger le fichier CSV dans un DataFrame
df = pd.read_csv(chemin_fichier_csv)

# Créer un dégradé de couleurs pour la palette
couleurs = sns.color_palette("coolwarm", as_cmap=True)

# Créer un diagramme circulaire (camembert) pour la variable 'nom_dept'
plt.figure(figsize=(10, 8))
sns.set(style="whitegrid")  # Style de fond pour une meilleure lisibilité

# Tracer le camembert avec le dégradé de couleurs
df['nom_dept'].value_counts().plot.pie(autopct='%1.1f%%', startangle=140, cmap=couleurs)
plt.title('Répartition des données par département')
plt.axis('equal')  # Assure que le camembert est dessiné comme un cercle
plt.ylabel('')  # Supprimer l'étiquette de l'axe y pour plus de clarté

plt.show()
```

## Résultat : {background-color="#CAFFEF"}

```{python}

#fonctionne camembert dégradé de couleur 
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import seaborn as sns
import os 

# Remplacez 'votre_fichier.csv' par le chemin vers votre fichier CSV
chemin_fichier_csv = 'Mesure_mensuelle_Region_Occitanie_Polluants_Principaux.csv'

# Charger le fichier CSV dans un DataFrame
df = pd.read_csv(chemin_fichier_csv)

# Créer un dégradé de couleurs pour la palette
couleurs = sns.color_palette("coolwarm", as_cmap=True)

# Créer un diagramme circulaire (camembert) pour la variable 'nom_dept'
plt.figure(figsize=(10, 8))
sns.set(style="whitegrid")  # Style de fond pour une meilleure lisibilité

# Tracer le camembert avec le dégradé de couleurs
df['nom_dept'].value_counts().plot.pie(autopct='%1.1f%%', startangle=140, cmap=couleurs)

plt.title('Répartition des données par département')
plt.axis('equal')  # Assure que le camembert est dessiné comme un cercle
plt.ylabel('')  # Supprimer l'étiquette de l'axe y pour plus de clarté

plt.show()
```

# Code carte intéractive : {background-color="#CAFFEF"}

```{.python code-line-numbers="2,3|6,7,8|11,12|15|24,25,26|59|68"}
#calcule de la valeur seuil 
moyenne_pollution = df['valeur'].mean()
ecart_type_pollution = df['valeur'].std()


print("Moyenne de la pollution:", moyenne_pollution)
print("Écart type de la pollution:", ecart_type_pollution)
print("Valeur la plus élevée:", seuil_valeur_elevee)

# Charger le fichier CSV dans un DataFrame
chemin_fichier_csv = 'Mesure_mensuelle_Region_Occitanie_Polluants_Principaux.csv'
df = pd.read_csv(chemin_fichier_csv)

# Créer une colonne 'geometry' avec les coordonnées X et Y sous forme de GeoJSON
df['geometry'] = df.apply(lambda row: {"type": "Point", "coordinates": [row['X'], row['Y']]}, axis=1)

# Valeur seuil
SEUIL_DE_VALEUR_ELEVEE = 23  

# Créer une carte avec le service WMTS
carte = Map(center=(43.611015, 3.876733), zoom=9)

# Ajouter une couche WMTS à la carte
wmts_url = "https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/WMTS"
wmts_layer = TileLayer(url=wmts_url, name="WMTS Layer")
carte.add_layer(wmts_layer)

# Créer une GeoJSON FeatureCollection à partir des données de votre DataFrame
geojson_data = {
    "type": "FeatureCollection",
    "features": []
}

# Marqueurs pour les valeurs élevées
high_value_markers = []

for index, row in df.iterrows():
    feature = {
        "type": "Feature",
        "geometry": row['geometry'],
        "properties": {"nom_dept": row['nom_dept'], "valeur": row['valeur']}
    }
    geojson_data['features'].append(feature)

    # Ajouter un marqueur si la valeur de pollution est élevée
    if row['valeur'] > SEUIL_DE_VALEUR_ELEVEE:
        marker = Marker(location=(row['Y'], row['X']), draggable=False, title=f"Valeur: {row['valeur']}")
        high_value_markers.append(marker)

# Créer une couche GeoJSON pour les zones polluées
geojson_layer = GeoJSON(data=geojson_data, style={'color': 'red', 'opacity': 0.8, 'weight': 1.5})
carte.add_layer(geojson_layer)

# Ajouter les marqueurs à la carte
for marker in high_value_markers:
    carte.add_layer(marker)

# Trouver l'indice de la valeur maximale dans la colonne 'valeur'
indice_max = df['valeur'].idxmax()

# Obtenir les coordonnées X et Y pour l'emplacement de la valeur maximale
coordonnees_max = df.loc[indice_max, ['X', 'Y']]

print("Coordonnées de l'endroit avec la valeur la plus élevée:", coordonnees_max)


# Afficher la carte 
display(widgets.HBox([carte]))


```


# Résultat : {background-color="#CAFFEF"}

```{python}

#calcule de la valeur seuil 
# Calculer la moyenne et l'écart type des valeurs de pollution
moyenne_pollution = df['valeur'].mean()
ecart_type_pollution = df['valeur'].std()

# Définir le seuil comme la moyenne plus 2 fois l'écart type
seuil_valeur_elevee = moyenne_pollution + 2 * ecart_type_pollution

print("Moyenne de la pollution:", moyenne_pollution)
print("Écart type de la pollution:", ecart_type_pollution)
print("Valeur la plus élevée:", seuil_valeur_elevee)


import pandas as pd
from ipyleaflet import Map, TileLayer, GeoJSON, Marker
import ipywidgets as widgets
from IPython.display import display

# Charger le fichier CSV dans un DataFrame
chemin_fichier_csv = 'Mesure_mensuelle_Region_Occitanie_Polluants_Principaux.csv'
df = pd.read_csv(chemin_fichier_csv)

# Créer une colonne 'geometry' avec les coordonnées X et Y sous forme de GeoJSON
df['geometry'] = df.apply(lambda row: {"type": "Point", "coordinates": [row['X'], row['Y']]}, axis=1)

# Valeur seuil
SEUIL_DE_VALEUR_ELEVEE = 23  

# Créer une carte avec le service WMTS
carte = Map(center=(43.611015, 3.876733), zoom=9)

# Ajouter une couche WMTS à la carte
wmts_url = "https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/WMTS"
wmts_layer = TileLayer(url=wmts_url, name="WMTS Layer")
carte.add_layer(wmts_layer)

# Créer une GeoJSON FeatureCollection à partir des données de votre DataFrame
geojson_data = {
    "type": "FeatureCollection",
    "features": []
}

# Marqueurs pour les valeurs élevées
high_value_markers = []

for index, row in df.iterrows():
    feature = {
        "type": "Feature",
        "geometry": row['geometry'],
        "properties": {"nom_dept": row['nom_dept'], "valeur": row['valeur']}
    }
    geojson_data['features'].append(feature)

    # Ajouter un marqueur si la valeur de pollution est élevée
    if row['valeur'] > SEUIL_DE_VALEUR_ELEVEE:
        marker = Marker(location=(row['Y'], row['X']), draggable=False, title=f"Valeur: {row['valeur']}")
        high_value_markers.append(marker)

# Créer une couche GeoJSON pour les zones polluées
geojson_layer = GeoJSON(data=geojson_data, style={'color': 'red', 'opacity': 0.8, 'weight': 1.5})
carte.add_layer(geojson_layer)

# Ajouter les marqueurs à la carte
# Ajouter les marqueurs à la carte
for marker in high_value_markers:
    carte.add_layer(marker)


# Créer une légende


# Afficher la carte avec la légende
display(widgets.HBox([carte]))

# Trouver l'indice de la valeur maximale dans la colonne 'valeur'
indice_max = df['valeur'].idxmax()

# Obtenir les coordonnées X et Y pour l'emplacement de la valeur maximale
coordonnees_max = df.loc[indice_max, ['X', 'Y']]

print("Coordonnées de l'endroit avec la valeur la plus élevée:", coordonnees_max)

```



# Hiérarchie des villes en fonction des polluants : {background-color="#CAFFEF"}

Tableau des scores 



# API Call : {background-color="#CAFFEF"}


```{.python code-line-numbers="51|52|1|2,3,4,5,6,7|53|10|23,24,25,26,27,28,29,30,31|34,35,36,37,38,39,40,41,42"}
def get_data(time):
    if time == "j":
        url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/Mesure_horaire_(30j)_Region_Occitanie_Polluants_Reglementaires_1/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json"
    elif time == "m":
        url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/mesures_occitanie_mensuelle_poll_princ/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json"
    response = requests.get(url)
    return response.json()


def extract_data_to_df(data: dict) -> pd.DataFrame:
    """extracts important data from dict and returns dataframe with data"""

    # get important data
    cities = []
    starts = []
    ends = []
    val = []
    poll_ue = []
    typo = []
    infl = []
    nom_poll = []

    for element in data["features"]:
        cities += [element.get("attributes").get("nom_com")]
        starts += [element.get("attributes").get("date_debut")]
        ends += [element.get("attributes").get("date_fin")]
        val += [element.get("attributes").get("valeur")]
        poll_ue += [element.get("attributes").get("id_poll_ue")]
        typo += [element.get("attributes").get("typologie")]
        infl += [element.get("attributes").get("influence")]
        nom_poll += [element.get("attributes").get("nom_poll")]

    # construct df from data
    df_data = pd.DataFrame()
    df_data["city"] = cities
    df_data["start"] = starts
    df_data["end"] = ends
    df_data["values"] = val
    df_data["poll_ue"] = poll_ue
    df_data["nom_poll"] = nom_poll
    df_data["influence"] = infl
    df_data["typology"] = typo

    # convert timestamps to dates
    df_data["start"] = df_data["start"].apply(lambda x: dt.fromtimestamp(x / 1e3))
    df_data["end"] = df_data["end"].apply(lambda x: dt.fromtimestamp(x / 1e3))

    return df_data


def data_prep(time):
    data = get_data(time=time)
    df = extract_data_to_df(data=data)
    return df
```